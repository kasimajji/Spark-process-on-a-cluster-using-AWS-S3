{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d8c95b-f745-47c2-9dc6-31fa1dc05e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from datetime import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import udf, col, monotonically_increasing_id\n",
    "from pyspark.sql.functions import year, month, dayofmonth, hour, weekofyear, date_format, dayofweek\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = config['AWS_ACCESS_KEY_ID']\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = config['AWS_SECRET_ACCESS_KEY']\n",
    "\n",
    "\n",
    "def create_spark_session():\n",
    "    spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "        .getOrCreate()\n",
    "    return spark\n",
    "\n",
    "\n",
    "def process_song_data(spark, input_data, output_data):\n",
    "\n",
    "    log_data = os.path.join(input_data, \"log-data/\")\n",
    "\n",
    "    df = spark.read.json(log_data, mode='PERMISSIVE', columnNameOfCorruptRecord='corrupt_record').drop_duplicates()\n",
    "\n",
    "    df = df.filter(df.page == \"NextSong\")\n",
    "\n",
    "    users_table = df.select(\"userId\",\"firstName\",\"lastName\",\"gender\",\"level\").drop_duplicates()\n",
    "\n",
    "    users_table.write.parquet(os.path.join(output_data, \"users/\") , mode=\"overwrite\")\n",
    "    get_timestamp = udf(lambda x : datetime.utcfromtimestamp(int(x)/1000), TimestampType())\n",
    "    df = df.withColumn(\"start_time\", get_timestamp(\"ts\"))\n",
    "    time_table = df.withColumn(\"hour\",hour(\"start_time\"))\\\n",
    "                    .withColumn(\"day\",dayofmonth(\"start_time\"))\\\n",
    "                    .withColumn(\"week\",weekofyear(\"start_time\"))\\\n",
    "                    .withColumn(\"month\",month(\"start_time\"))\\\n",
    "                    .withColumn(\"year\",year(\"start_time\"))\\\n",
    "                    .withColumn(\"weekday\",dayofweek(\"start_time\"))\\\n",
    "                    .select(\"ts\",\"start_time\",\"hour\", \"day\", \"week\", \"month\", \"year\", \"weekday\").drop_duplicates()\n",
    "    time_table.write.parquet(os.path.join(output_data, \"time_table/\"), mode='overwrite', partitionBy=[\"year\",\"month\"])\n",
    "\n",
    "    song_df = spark.read\\\n",
    "                .format(\"parquet\")\\\n",
    "                .option(\"basePath\", os.path.join(output_data, \"songs/\"))\\\n",
    "                .load(os.path.join(output_data, \"songs/*/*/\"))\n",
    "\n",
    "    songplays_table = df.join(song_df, df.song == song_df.title, how='inner')\\\n",
    "                        .select(monotonically_increasing_id().alias(\"songplay_id\"),col(\"start_time\"),col(\"userId\").alias(\"user_id\"),\"level\",\"song_id\",\"artist_id\", col(\"sessionId\").alias(\"session_id\"), \"location\", col(\"userAgent\").alias(\"user_agent\"))\n",
    "\n",
    "    songplays_table = songplays_table.join(time_table, songplays_table.start_time == time_table.start_time, how=\"inner\")\\\n",
    "                        .select(\"songplay_id\", songplays_table.start_time, \"user_id\", \"level\", \"song_id\", \"artist_id\", \"session_id\", \"location\", \"user_agent\", \"year\", \"month\")\n",
    "\n",
    "    songplays_table.drop_duplicates().write.parquet(os.path.join(output_data, \"songplays/\"), mode=\"overwrite\", partitionBy=[\"year\",\"month\"])\n",
    "\n",
    "\n",
    "def main():\n",
    "    spark = create_spark_session()\n",
    "    input_data = \"s3://songs-spark-project/\"\n",
    "    output_data = \"s3://songs-spark-project/output/\"\n",
    "\n",
    "    process_song_data(spark, input_data, output_data)\n",
    "    process_log_data(spark, input_data, output_data)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
